#version 450

#include "tonemap_bindings.h"

layout(set = RESULT_IMAGE_SET, binding = RESULT_IMAGE_BINDING) uniform writeonly image2D uTonemapResultImage;
layout(set = SOURCE_IMAGE_SET, binding = SOURCE_IMAGE_BINDING) uniform sampler2D uSourceTexture;

layout(set = LUMINANCE_VALUES_SET, binding = LUMINANCE_VALUES_BINDING) buffer LUMINANCE_VALUES
{
    float uLuminanceValues[];
};

layout(push_constant) uniform PUSH_CONSTS 
{
	PushConsts uPushConsts;
};

layout (local_size_x = 8, local_size_y = 8, local_size_z = 1) in;

const float A = 0.15; // shoulder strength
const float B = 0.50; // linear strength
const float C = 0.10; // linear angle
const float D = 0.20; // toe strength
const float E = 0.02; // toe numerator
const float F = 0.30; // toe denominator
const vec3 W = vec3(11.2); // linear white point value

const float PQ_constant_N = (2610.0 / 4096.0 / 4.0);
const float PQ_constant_M = (2523.0 / 4096.0 * 128.0);
const float PQ_constant_C1 = (3424.0 / 4096.0);
const float PQ_constant_C2 = (2413.0 / 4096.0 * 32.0);
const float PQ_constant_C3 = (2392.0 / 4096.0 * 32.0);

vec3 uncharted2Tonemap(vec3 x)
{
   return ((x*(A*x+C*B)+D*E)/(x*(A*x+B)+D*F))-E/F;
}

vec3 accurateLinearToSRGB(in vec3 linearCol)
{
	vec3 sRGBLo = linearCol * 12.92;
	vec3 sRGBHi = (pow(abs(linearCol), vec3(1.0/2.4)) * 1.055) - 0.055;
	vec3 sRGB = mix(sRGBLo, sRGBHi, vec3(greaterThan(linearCol, vec3(0.0031308))));
	return sRGB;
}

float computeEV100(float aperture, float shutterTime, float ISO)
{
	// EV number is defined as:
	// 2^EV_s = N^2 / t and EV_s = EV_100 + log2(S/100)
	// This gives
	//   EV_s = log2(N^2 / t)
	//   EV_100 + log2(S/100) = log(N^2 / t)
	//   EV_100 = log2(N^2 / t) - log2(S/100)
	//   EV_100 = log2(N^2 / t * 100 / S)
	return log2((aperture * aperture) / shutterTime * 100 / ISO);
}

float computeEV100FromAvgLuminance(float avgLuminance)
{
	// We later use the middle gray at 12.7% in order to have
	// a middle gray at 12% with a sqrt(2) room for specular highlights
	// But here we deal with the spot meter measuring the middle gray
	// which is fixed at 12.5 for matching standard camera
	// constructor settings (i.e. calibration constant K = 12.5)
	// Reference: http://en.wikipedia.org/wiki/Film_speed
	return log2(max(avgLuminance, 1e-5) * 100.0 / 12.5);
}

float convertEV100ToExposure(float EV100)
{
	// Compute the maximum luminance possible with H_sbs sensitivity
	// maxLum = 78 / ( S * q ) * N^2 / t
	//        = 78 / ( S * q ) * 2^EV_100
	//        = 78 / ( 100 * 0.65) * 2^EV_100
	//        = 1.2 * 2^EV
	// Reference: http://en.wikipedia.org/wiki/Film_speed
	float maxLuminance = 1.2 * pow(2.0, EV100);
	return 1.0 / maxLuminance;
}

// Aplies exponential ("Photographic") luma compression
float rangeCompress(float x)
{
    return 1.0 - exp(-x);
}

float rangeCompress(float val, float threshold)
{
    float v1 = val;
    float v2 = threshold + (1 - threshold) * rangeCompress((val - threshold) / (1 - threshold));
    return val < threshold ? v1 : v2;
}

vec3 rangeCompress(vec3 val, float threshold)
{
    return vec3(
        rangeCompress(val.x, threshold),
        rangeCompress(val.y, threshold),
        rangeCompress(val.z, threshold));
}

// PQ (Perceptual Quantiser; ST.2084) encode/decode used for HDR TV and grading
vec3 linearToPQ(vec3 linearCol, const float maxPqValue)
{
    linearCol /= maxPqValue;

    vec3 colToPow = pow(linearCol, vec3(PQ_constant_N));
    vec3 numerator = PQ_constant_C1 + PQ_constant_C2*colToPow;
    vec3 denominator = 1.0 + PQ_constant_C3*colToPow;
    vec3 pq = pow(numerator / denominator, vec3(PQ_constant_M));

    return pq;
}

vec3 PQtoLinear(vec3 linearCol, const float maxPqValue)
{
    vec3 colToPow = pow(linearCol, vec3(1.0 / PQ_constant_M));
    vec3 numerator = max(colToPow - PQ_constant_C1, 0.0);
    vec3 denominator = PQ_constant_C2 - (PQ_constant_C3 * colToPow);
    vec3 linearColor = pow(numerator / denominator, vec3(1.0 / PQ_constant_N));

    linearColor *= maxPqValue;

    return linearColor;
}

// RGB with sRGB/Rec.709 primaries to CIE XYZ
vec3 RGBToXYZ(vec3 c)
{
    mat3 mat = mat3(
        0.4124564,  0.3575761,  0.1804375,
        0.2126729,  0.7151522,  0.0721750,
        0.0193339,  0.1191920,  0.9503041
    );
    return c * mat;
}

vec3 XYZToRGB(vec3 c)
{
    mat3 mat = mat3(
         3.24045483602140870, -1.53713885010257510, -0.49853154686848090,
        -0.96926638987565370,  1.87601092884249100,  0.04155608234667354,
         0.05564341960421366, -0.20402585426769815,  1.05722516245792870
    );
    return c * mat;
}
// Converts XYZ tristimulus values into cone responses for the three types of cones in the human visual system, matching long, medium, and short wavelengths.
// Note that there are many LMS color spaces; this one follows the ICtCp color space specification.
vec3 XYZToLMS(vec3 c)
{
    mat3 mat = mat3(
        0.3592,  0.6976, -0.0358,
        -0.1922, 1.1004,  0.0755,
        0.0070,  0.0749,  0.8434
    ); 
    return c * mat;
}

vec3 LMSToXYZ(vec3 c)
{
    mat3 mat = mat3(
         2.07018005669561320, -1.32645687610302100,  0.206616006847855170,
         0.36498825003265756,  0.68046736285223520, -0.045421753075853236,
        -0.04959554223893212, -0.04942116118675749,  1.187995941732803400
    );
    return c * mat;
}

// RGB with sRGB/Rec.709 primaries to ICtCp
vec3 RGBToICtCp(vec3 col)
{
    col = RGBToXYZ(col);
    col = XYZToLMS(col);
    // 1.0f = 100 nits, 100.0f = 10k nits
    col = linearToPQ(max(0.0.xxx, col), 100.0);

    // Convert PQ-LMS into ICtCp. Note that the "S" channel is not used,
    // but overlap between the cone responses for long, medium, and short wavelengths
    // ensures that the corresponding part of the spectrum contributes to luminance.

    mat3 mat = mat3(
        0.5000,  0.5000,  0.0000,
        1.6137, -3.3234,  1.7097,
        4.3780, -4.2455, -0.1325
    );

    return col * mat;
}

vec3 ICtCpToRGB(vec3 col)
{
    mat3 mat = mat3(
        1.0,  0.00860514569398152,  0.11103560447547328,
        1.0, -0.00860514569398152, -0.11103560447547328,
        1.0,  0.56004885956263900, -0.32063747023212210
    );
    col = col * mat;

    // 1.0f = 100 nits, 100.0f = 10k nits
    col = PQtoLinear(col, 100.0);
    col = LMSToXYZ(col);
    return XYZToRGB(col);
}

vec3 applyHuePreservingShoulder(vec3 col)
{
    vec3 ictcp = RGBToICtCp(col);

    // Hue-preserving range compression requires desaturation in order to achieve a natural look. We adaptively desaturate the input based on its luminance.
    float saturationAmount = pow(smoothstep(1.0, 0.3, ictcp.x), 1.3);
    col = ICtCpToRGB(ictcp * vec3(1, saturationAmount.xx));

    // Only compress luminance starting at a certain point. Dimmer inputs are passed through without modification.
    float linearSegmentEnd = 0.25;

    // Hue-preserving mapping
    float maxCol = max(col.x, max(col.y, col.z));
    float mappedMax = rangeCompress(maxCol, linearSegmentEnd);
    vec3 compressedHuePreserving = col * mappedMax / maxCol;

    // Non-hue preserving mapping
    vec3 perChannelCompressed = rangeCompress(col, linearSegmentEnd);

    // Combine hue-preserving and non-hue-preserving colors. Absolute hue preservation looks unnatural, as bright colors *appear* to have been hue shifted.
    // Actually doing some amount of hue shifting looks more pleasing
    col = mix(perChannelCompressed, compressedHuePreserving, 0.6);

    vec3 ictcpMapped = RGBToICtCp(col);

    // Smoothly ramp off saturation as brightness increases, but keep some even for very bright input
    float postCompressionSaturationBoost = 0.3 * smoothstep(1.0, 0.5, ictcp.x);

    // Re-introduce some hue from the pre-compression color. Something similar could be accomplished by delaying the luma-dependent desaturation before range compression.
    // Doing it here however does a better job of preserving perceptual luminance of highly saturated colors. Because in the hue-preserving path we only range-compress the max channel,
    // saturated colors lose luminance. By desaturating them more aggressively first, compressing, and then re-adding some saturation, we can preserve their brightness to a greater extent.
    ictcpMapped.yz = mix(ictcpMapped.yz, ictcp.yz * ictcpMapped.x / max(1e-3, ictcp.x), postCompressionSaturationBoost);

    col = ICtCpToRGB(ictcpMapped);

    return col;
}


void main() 
{
	vec3 color = texelFetch(uSourceTexture, ivec2(gl_GlobalInvocationID.xy), 0).rgb;
	
	float avgLuminance = uLuminanceValues[uPushConsts.luminanceIndex];
	//float EV100 = computeEV100(16.0, 0.01, 100);
	float EV100 = computeEV100FromAvgLuminance(avgLuminance);
	EV100 -= 1.0;
	color *= convertEV100ToExposure(EV100);

	color = applyHuePreservingShoulder(color);
	//float exposureBias = 1.0;
	//color = uncharted2Tonemap(exposureBias * color);
	//vec3 whiteScale = 1.0/uncharted2Tonemap(W);
	//color *= whiteScale;
    // gamma correct
	if (uPushConsts.applyLinearToGamma != 0)
	{
		color = accurateLinearToSRGB(color);//pow(color, vec3(1.0/2.2));
	}
	
	imageStore(uTonemapResultImage, ivec2(gl_GlobalInvocationID.xy), vec4(color, dot(color.rgb, vec3(0.299, 0.587, 0.114))));
}